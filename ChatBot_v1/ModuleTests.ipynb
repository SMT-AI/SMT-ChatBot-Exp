{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a46a61-ae47-4d1c-8692-4eb3b5183426",
   "metadata": {},
   "source": [
    "# BERT Intent Classifier Module Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ef8e4c-dcdd-4065-9e33-5f32c0d006fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BERTClassifier import IntentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840c6595-045a-4e61-aa0c-678ca6034914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 17:37:49,971 - BERTClassifier - INFO - Using device: cpu\n",
      "2025-02-18 17:37:51,079 - BERTClassifier - INFO - Model successfully loaded from ../PT_NLU_Test1/models/erp_bot_t1.pt\n"
     ]
    }
   ],
   "source": [
    "classifier = IntentClassifier(\n",
    "    model_path='../PT_NLU_Test1/models/erp_bot_t1.pt',\n",
    "    confidence_threshold=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f95c0ec3-9f31-4167-9ce5-1d2594b94d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'llm_fallback',\n",
       " 'confidence': {'main': 0.16361722350120544, 'sub': 0.0},\n",
       " 'original_query': 'How to make my professor sick?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(\"How to make my professor sick?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101d50a-e5ec-4f97-94c9-a20dec755cfd",
   "metadata": {},
   "source": [
    "# LLM Gateway (Ollama Server) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aaaaabb-fabc-4c57-a77f-94fe84c0b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLM_Gateway_Ollama import LLMGateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d368803-17f6-4a35-9ca2-12297c426c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 17:39:37,456 - LLM_Gateway_Ollama - INFO - Successfully connected to Ollama server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gateway initialized successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gateway = LLMGateway(\n",
    "        base_url=\"http://127.0.0.1:11434\",  # Default Ollama port\n",
    "        model=\"llama3.2:1b\",                   \n",
    "        temperature=0.7,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    print(\"✓ Gateway initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Gateway initialization failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "338f9c64-20e8-4587-8db1-87a1902863c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "        \"No, I want my proffesor sick so that I can skip tomorrow's test. Please help me!\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7bbf626-fbb1-4405-aac8-3c16943cfcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing queries:\n",
      "\n",
      "Query: No, I want my proffesor sick so that I can skip tomorrow's test. Please help me!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 17:53:30,117 - LLM_Gateway_Ollama - INFO - Parameters updated - Temperature: 0.9, Max Tokens: 600\n",
      "2025-02-18 17:53:30,118 - LLM_Gateway_Ollama - INFO - Model changed to: llama3.2:1b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Response: I can't assist with requesting your professor to be ill or missing class without legitimate reasons. If you need help with a different query or require assistance with a legitimate issue, feel free to ask.\n",
      "\n",
      "Testing parameter updates:\n",
      "✓ Parameters updated successfully\n",
      "\n",
      "Testing model change:\n",
      "✓ Model changed successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting queries:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    result = gateway.generate_response(\"For the following query answer only within 50 words: \" + query) #Pre-Promp fixed\n",
    "    print(f\"Status: {result['status']}\")\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"Response: {result['response'][:1000]}\")  #First 1000 words (clipping)\n",
    "    else:\n",
    "        print(f\"Error: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "#Test parameter updates\n",
    "print(\"\\nTesting parameter updates:\")\n",
    "try:\n",
    "    gateway.set_parameters(temperature=0.9, max_tokens=600)\n",
    "    print(\"✓ Parameters updated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Parameter update failed: {str(e)}\")\n",
    "\n",
    "# Test model change\n",
    "print(\"\\nTesting model change:\")\n",
    "try:\n",
    "    gateway.set_model(\"llama3.2:1b\")  # Or any other model you have\n",
    "    print(\"✓ Model changed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Model change failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758c4ce-1b3c-480c-bdbf-423f324e5189",
   "metadata": {},
   "source": [
    "# Corpus Manager Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eedbb32-0640-4211-bf8f-3d8d3c93d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpus_Manager import CorpusManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dba7ded-3bf9-4228-aa1b-1e4099aa9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:07:23,237 - Corpus_Manager - INFO - Successfully loaded corpus from corpus.json\n",
      "2025-02-18 18:07:23,238 - Corpus_Manager - ERROR - Main intent 'invalid_intent' not found in corpus\n",
      "2025-02-18 18:07:23,238 - Corpus_Manager - ERROR - Sub-intent 'invalid_sub_intent' not found under main intent 'admission_process'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Corpus Manager initialized successfully\n",
      "\n",
      "Validating corpus structure:\n",
      "Validation status: success\n",
      "\n",
      "Testing response retrieval:\n",
      "\n",
      "Test case - Main: admission_process, Sub: admission_deadline\n",
      "Status: success\n",
      "Main response: Hello! The admission process at [Institution Name] ...\n",
      "Sub response: The admission deadline for [Course/Program] at [In ...\n",
      "\n",
      "Test case - Main: admission_process, Sub: None\n",
      "Status: success\n",
      "Main response: Hello! The admission process at [Institution Name] ...\n",
      "\n",
      "Test case - Main: invalid_intent, Sub: None\n",
      "Status: error\n",
      "Error: Main intent 'invalid_intent' not found in corpus\n",
      "\n",
      "Test case - Main: admission_process, Sub: invalid_sub_intent\n",
      "Status: error\n",
      "Error: Sub-intent 'invalid_sub_intent' not found under main intent 'admission_process'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    manager = CorpusManager('corpus.json')\n",
    "    print(\"✓ Corpus Manager initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Corpus Manager initialization failed: {str(e)}\")\n",
    "\n",
    "# Test validation\n",
    "print(\"\\nValidating corpus structure:\")\n",
    "validation_result = manager.validate_intent_structure()\n",
    "print(f\"Validation status: {validation_result['status']}\")\n",
    "if validation_result['errors']:\n",
    "    print(\"Validation errors:\")\n",
    "    for error in validation_result['errors']:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    # Valid main and sub intent\n",
    "    ('admission_process', 'admission_deadline'),\n",
    "    # Valid main intent only\n",
    "    ('admission_process', None),\n",
    "    # Invalid main intent\n",
    "    ('invalid_intent', None),\n",
    "    # Invalid sub intent\n",
    "    ('admission_process', 'invalid_sub_intent'),\n",
    "]\n",
    "\n",
    "print(\"\\nTesting response retrieval:\")\n",
    "for main_intent, sub_intent in test_cases:\n",
    "    print(f\"\\nTest case - Main: {main_intent}, Sub: {sub_intent}\")\n",
    "    result = manager.get_response_text(main_intent, sub_intent)\n",
    "    print(f\"Status: {result['status']}\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(\"Main response:\", result['main_response'][:50], \"...\")\n",
    "        if result['sub_response']:\n",
    "            print(\"Sub response:\", result['sub_response'][:50], \"...\")\n",
    "    else:\n",
    "        print(\"Error:\", result.get('error', 'Unknown error'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c586842-b7db-420e-9435-53b62a4cf670",
   "metadata": {},
   "source": [
    "# Overall Test Before API/Containerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9191f24-ee63-440c-aae5-280dbdceb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Any\n",
    "from BERTClassifier import IntentClassifier\n",
    "from LLM_Gateway_Ollama import LLMGateway\n",
    "from Corpus_Manager import CorpusManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60408fe3-2e6e-4244-947e-e944583e65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ChatbotPipeline:\n",
    "    \"\"\"Test pipeline integrating all modules\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_path: str,\n",
    "                 corpus_path: str,\n",
    "                 confidence_threshold: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the test pipeline.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to BERT model\n",
    "            corpus_path: Path to corpus JSON\n",
    "            confidence_threshold: Confidence threshold for intent classification\n",
    "        \"\"\"\n",
    "        # Initialize all components\n",
    "        logger.info(\"Initializing components...\")\n",
    "        \n",
    "        self.classifier = IntentClassifier(\n",
    "            model_path=model_path,\n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "        \n",
    "        self.llm = LLMGateway(\n",
    "            base_url=\"http://127.0.0.1:11434\",\n",
    "            model=\"llama3.2:1b\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        self.corpus = CorpusManager(corpus_path)\n",
    "        logger.info(\"All components initialized successfully\")\n",
    "\n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a single query through the pipeline.\n",
    "        \n",
    "        Args:\n",
    "            query: User query text\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing processing results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Processing query: {query}\")\n",
    "            \n",
    "            # Step 1: Intent Classification\n",
    "            classification_result = self.classifier.predict(query)\n",
    "            logger.info(f\"Classification result: {classification_result}\")\n",
    "            \n",
    "            # Check if we should use LLM\n",
    "            if classification_result['status'] == 'llm_fallback':\n",
    "                logger.info(\"Query classified for LLM fallback\")\n",
    "                llm_response = self.llm.generate_response(\"For the following query answer within 50 words (DON'T OUTPUT THIS REQUIREMENT AT ANY COST): \"+ query)\n",
    "                \n",
    "                return {\n",
    "                    'status': 'success',\n",
    "                    'source': 'llm',\n",
    "                    'response': llm_response.get('response'),\n",
    "                    'confidence': classification_result['confidence']\n",
    "                }\n",
    "            \n",
    "            # Step 2: Get response from corpus\n",
    "            elif classification_result['status'] == 'success':\n",
    "                logger.info(\"Query matched known intents, fetching from corpus\")\n",
    "                corpus_response = self.corpus.get_response_text(\n",
    "                    classification_result['main_intent'],\n",
    "                    classification_result['sub_intent']\n",
    "                )\n",
    "                \n",
    "                if corpus_response['status'] == 'success':\n",
    "                    return {\n",
    "                        'status': 'success',\n",
    "                        'source': 'corpus',\n",
    "                        'main_response': corpus_response['main_response'],\n",
    "                        'sub_response': corpus_response['sub_response'],\n",
    "                        'confidence': classification_result['confidence'],\n",
    "                        'intents': {\n",
    "                            'main': classification_result['main_intent'],\n",
    "                            'sub': classification_result['sub_intent']\n",
    "                        }\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        'status': 'error',\n",
    "                        'error': f\"Corpus error: {corpus_response.get('error')}\",\n",
    "                        'confidence': classification_result['confidence']\n",
    "                    }\n",
    "            \n",
    "            # Handle classification errors\n",
    "            else:\n",
    "                return {\n",
    "                    'status': 'error',\n",
    "                    'error': f\"Classification error: {classification_result.get('error')}\",\n",
    "                    'confidence': classification_result.get('confidence', {'main': 0.0, 'sub': 0.0})\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {str(e)}\")\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error': f\"Processing error: {str(e)}\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c327b4d-9a70-4c3d-b839-34af8f807606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:22,413 - __main__ - INFO - Initializing components...\n",
      "2025-02-19 09:24:22,414 - BERTClassifier - INFO - Using device: cpu\n",
      "2025-02-19 09:24:24,680 - BERTClassifier - INFO - Model successfully loaded from ../PT_NLU_Test1/models/erp_bot_t1.pt\n",
      "2025-02-19 09:24:24,697 - LLM_Gateway_Ollama - INFO - Successfully connected to Ollama server\n",
      "2025-02-19 09:24:24,698 - Corpus_Manager - INFO - Successfully loaded corpus from corpus.json\n",
      "2025-02-19 09:24:24,698 - __main__ - INFO - All components initialized successfully\n",
      "2025-02-19 09:24:24,699 - __main__ - INFO - Processing query: What's the deadline for admission?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pipeline initialized successfully\n",
      "\n",
      "\n",
      "Test Case 1: 'What's the deadline for admission?'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:24,979 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'admission_process', 'sub_intent': 'admission_deadline', 'confidence': {'main': 0.9378741383552551, 'sub': 0.4921603798866272}}\n",
      "2025-02-19 09:24:24,980 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-19 09:24:24,980 - __main__ - INFO - Processing query: How to register for the sports team?\n",
      "2025-02-19 09:24:25,093 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'sports_registration', 'sub_intent': 'registration_process', 'confidence': {'main': 0.8812710046768188, 'sub': 0.5937088131904602}}\n",
      "2025-02-19 09:24:25,094 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-19 09:24:25,094 - __main__ - INFO - Processing query: How to check the holidays on the timetable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The admission process at [Institution Name] involves several steps, including application submission, document verification, fee payment, and confirmation. How can I assist you with the admission process?\n",
      "\n",
      "Sub Intent Response:\n",
      "The admission deadline for [Course/Program] at [Institution Name] is [Deadline Date]. Ensure that you complete all necessary steps before this date. Would you like more details?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9379\n",
      "  Sub:  0.4922\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 2: 'How to register for the sports team?'\n",
      "--------------------------------------------------\n",
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! If you’re interested in joining a sports team or activity at [Institution Name], you can register through [Sports Registration Portal Link]. How can I assist you with the registration process?\n",
      "\n",
      "Sub Intent Response:\n",
      "The sports registration process involves the following steps:\n",
      "1. Fill out the registration form at [Sports Registration Portal Link].\n",
      "2. Submit any required documents (medical certificate, consent form, etc.).\n",
      "3. Attend trials or selection rounds if applicable.\n",
      "Would you like help with completing your registration?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.8813\n",
      "  Sub:  0.5937\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 3: 'How to check the holidays on the timetable?'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:25,209 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'class_timetable', 'sub_intent': 'timetable_conflicts', 'confidence': {'main': 0.9623135924339294, 'sub': 0.28755855560302734}}\n",
      "2025-02-19 09:24:25,209 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-19 09:24:25,210 - __main__ - INFO - Processing query: How can I pay fee online?\n",
      "2025-02-19 09:24:25,321 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'fee_details', 'sub_intent': 'fee_deadline', 'confidence': {'main': 0.9466932415962219, 'sub': 0.3009275794029236}}\n",
      "2025-02-19 09:24:25,322 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-19 09:24:25,322 - __main__ - INFO - Processing query: How to make my professor sick so that I can avoid tomorrow's class test?\n",
      "2025-02-19 09:24:25,394 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.4073396623134613, 'sub': 0.0}, 'original_query': \"How to make my professor sick so that I can avoid tomorrow's class test?\"}\n",
      "2025-02-19 09:24:25,394 - __main__ - INFO - Query classified for LLM fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! You can access your class timetable for [Course/Program] at [Institution Name] by visiting [Timetable Portal Link]. How can I assist you with your timetable?\n",
      "\n",
      "Sub Intent Response:\n",
      "If your timetable has conflicting classes, you can resolve the issue by:\n",
      "1. Contacting your academic advisor or course coordinator.\n",
      "2. Requesting a timetable adjustment at [Conflict Resolution Link].\n",
      "Would you like guidance on resolving timetable conflicts?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9623\n",
      "  Sub:  0.2876\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 4: 'How can I pay fee online?'\n",
      "--------------------------------------------------\n",
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The fee details for [Course/Program] at [Institution Name] include tuition fees, examination fees, and other applicable charges. How can I assist you with fee-related information?\n",
      "\n",
      "Sub Intent Response:\n",
      "The fee payment deadline for [Course/Program] is [Deadline Date]. Ensure that you complete the payment before this date to avoid penalties. Would you like more details?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9467\n",
      "  Sub:  0.3009\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 5: 'How to make my professor sick so that I can avoid tomorrow's class test?'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:25,541 - __main__ - INFO - Processing query: Tell me a joke about RUST programming\n",
      "2025-02-19 09:24:25,602 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.11446689069271088, 'sub': 0.0}, 'original_query': 'Tell me a joke about RUST programming'}\n",
      "2025-02-19 09:24:25,603 - __main__ - INFO - Query classified for LLM fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "I can't provide information or guidance on harmful behavior such as trying to make your professor sick. Can I help you with something else?\n",
      "\n",
      "Confidence Score: 0.4073\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 6: 'Tell me a joke about RUST programming'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:25,899 - __main__ - INFO - Processing query: How to calculate 5 times 6?\n",
      "2025-02-19 09:24:25,960 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.14254972338676453, 'sub': 0.0}, 'original_query': 'How to calculate 5 times 6?'}\n",
      "2025-02-19 09:24:25,960 - __main__ - INFO - Query classified for LLM fallback\n",
      "2025-02-19 09:24:26,095 - __main__ - INFO - Processing query: \n",
      "2025-02-19 09:24:26,096 - __main__ - INFO - Classification result: {'status': 'error', 'error': 'Empty or invalid input text', 'confidence': {'main': 0.0, 'sub': 0.0}}\n",
      "2025-02-19 09:24:26,096 - __main__ - INFO - Processing query: ???\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "Why did the Rust programmer break up with his girlfriend?\n",
      "\n",
      "Because he wanted to \"type\" their relationship was over. Now she's \"panic-ulating\" him, and he's just trying to \"build\" a new life without her. He's now coding in silence, fearing someone will \"crash\" his heart.\n",
      "\n",
      "Confidence Score: 0.1145\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 7: 'How to calculate 5 times 6?'\n",
      "--------------------------------------------------\n",
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "To calculate 5 times 6, you multiply 5 by 6, which equals 30.\n",
      "\n",
      "Confidence Score: 0.1425\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 8: ''\n",
      "--------------------------------------------------\n",
      "Status: error\n",
      "Source: N/A\n",
      "Error: Classification error: Empty or invalid input text\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 9: '???'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:26,156 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.2581322193145752, 'sub': 0.0}, 'original_query': '???'}\n",
      "2025-02-19 09:24:26,157 - __main__ - INFO - Query classified for LLM fallback\n",
      "2025-02-19 09:24:26,465 - __main__ - INFO - Processing query: I need help with my admission but I'm not sure what exactly to ask\n",
      "2025-02-19 09:24:26,602 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'admission_process', 'sub_intent': 'admission_status', 'confidence': {'main': 0.9397178888320923, 'sub': 0.4698791205883026}}\n",
      "2025-02-19 09:24:26,602 - __main__ - INFO - Query matched known intents, fetching from corpus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "I can reformat your question to fit within the 50-word limit. Here's the revised version:\n",
      "\n",
      "\"Write a SQL query that selects all columns from a table named 'employees' where the employee ID is between 1000 and 2000, and the employee name starts with 'John'. Also, return only the date of birth and salary.\"\n",
      "\n",
      "Confidence Score: 0.2581\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 10: 'I need help with my admission but I'm not sure what exactly to ask'\n",
      "--------------------------------------------------\n",
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The admission process at [Institution Name] involves several steps, including application submission, document verification, fee payment, and confirmation. How can I assist you with the admission process?\n",
      "\n",
      "Sub Intent Response:\n",
      "You can check your admission status by visiting [Admission Portal Link] and entering your application number. Would you like me to guide you through the process?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9397\n",
      "  Sub:  0.4699\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pipeline = ChatbotPipeline(\n",
    "        model_path='../PT_NLU_Test1/models/erp_bot_t1.pt',\n",
    "        corpus_path='corpus.json',\n",
    "        confidence_threshold=0.7\n",
    "    )\n",
    "    print(\"✓ Pipeline initialized successfully\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Pipeline initialization failed: {str(e)}\")\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    # In-domain queries (should use corpus)\n",
    "    \"What's the deadline for admission?\",\n",
    "    \"How to register for the sports team?\",\n",
    "    \"How to check the holidays on the timetable?\",\n",
    "    \"How can I pay fee online?\",\n",
    "    \n",
    "    #Out-of-domain queries (should use LLM)\n",
    "    \"How to make my professor sick so that I can avoid tomorrow's class test?\",\n",
    "    \"Tell me a joke about RUST programming\",\n",
    "    \"How to calculate 5 times 6?\",\n",
    "    \n",
    "    #Edge cases\n",
    "    \"\",  # Empty query\n",
    "    \"???\",  # Nonsense query\n",
    "    \"I need help with my admission but I'm not sure what exactly to ask\"  # Ambiguous query\n",
    "]\n",
    "\n",
    "# Process each test query\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nTest Case {i}: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    result = pipeline.process_query(query)\n",
    "    \n",
    "    print(f\"Status: {result['status']}\")\n",
    "    print(f\"Source: {result.get('source', 'N/A')}\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        if result['source'] == 'corpus':\n",
    "            print(\"\\nMain Intent Response:\")\n",
    "            print(result['main_response'])\n",
    "            if result['sub_response']:\n",
    "                print(\"\\nSub Intent Response:\")\n",
    "                print(result['sub_response'])\n",
    "            print(f\"\\nConfidence Scores:\")\n",
    "            print(f\"  Main: {result['confidence']['main']:.4f}\")\n",
    "            print(f\"  Sub:  {result['confidence']['sub']:.4f}\")\n",
    "        else:  # LLM response\n",
    "            print(\"\\nLLM Response:\")\n",
    "            print(result['response'])\n",
    "            print(f\"\\nConfidence Score: {result['confidence']['main']:.4f}\")\n",
    "    else:\n",
    "        print(f\"Error: {result.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40422e2a-c212-41a0-a904-4dac9042fb93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
