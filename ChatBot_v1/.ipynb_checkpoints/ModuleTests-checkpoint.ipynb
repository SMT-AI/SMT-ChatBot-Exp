{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a46a61-ae47-4d1c-8692-4eb3b5183426",
   "metadata": {},
   "source": [
    "# BERT Intent Classifier Module Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ef8e4c-dcdd-4065-9e33-5f32c0d006fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BERTClassifier import IntentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840c6595-045a-4e61-aa0c-678ca6034914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 17:37:49,971 - BERTClassifier - INFO - Using device: cpu\n",
      "2025-02-18 17:37:51,079 - BERTClassifier - INFO - Model successfully loaded from ../PT_NLU_Test1/models/erp_bot_t1.pt\n"
     ]
    }
   ],
   "source": [
    "classifier = IntentClassifier(\n",
    "    model_path='../PT_NLU_Test1/models/erp_bot_t1.pt',\n",
    "    confidence_threshold=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f95c0ec3-9f31-4167-9ce5-1d2594b94d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'llm_fallback',\n",
       " 'confidence': {'main': 0.16361722350120544, 'sub': 0.0},\n",
       " 'original_query': 'How to make my professor sick?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(\"How to make my professor sick?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101d50a-e5ec-4f97-94c9-a20dec755cfd",
   "metadata": {},
   "source": [
    "# LLM Gateway (Ollama Server) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aaaaabb-fabc-4c57-a77f-94fe84c0b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLM_Gateway_Ollama import LLMGateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d368803-17f6-4a35-9ca2-12297c426c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 17:39:37,456 - LLM_Gateway_Ollama - INFO - Successfully connected to Ollama server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gateway initialized successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gateway = LLMGateway(\n",
    "        base_url=\"http://127.0.0.1:11434\",  # Default Ollama port\n",
    "        model=\"llama3.2:1b\",                   \n",
    "        temperature=0.7,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    print(\"✓ Gateway initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Gateway initialization failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "338f9c64-20e8-4587-8db1-87a1902863c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "        \"No, I want my proffesor sick so that I can skip tomorrow's test. Please help me!\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7bbf626-fbb1-4405-aac8-3c16943cfcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing queries:\n",
      "\n",
      "Query: No, I want my proffesor sick so that I can skip tomorrow's test. Please help me!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 17:53:30,117 - LLM_Gateway_Ollama - INFO - Parameters updated - Temperature: 0.9, Max Tokens: 600\n",
      "2025-02-18 17:53:30,118 - LLM_Gateway_Ollama - INFO - Model changed to: llama3.2:1b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Response: I can't assist with requesting your professor to be ill or missing class without legitimate reasons. If you need help with a different query or require assistance with a legitimate issue, feel free to ask.\n",
      "\n",
      "Testing parameter updates:\n",
      "✓ Parameters updated successfully\n",
      "\n",
      "Testing model change:\n",
      "✓ Model changed successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting queries:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    result = gateway.generate_response(\"For the following query answer only within 50 words: \" + query) #Pre-Promp fixed\n",
    "    print(f\"Status: {result['status']}\")\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"Response: {result['response'][:1000]}\")  #First 1000 words (clipping)\n",
    "    else:\n",
    "        print(f\"Error: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "#Test parameter updates\n",
    "print(\"\\nTesting parameter updates:\")\n",
    "try:\n",
    "    gateway.set_parameters(temperature=0.9, max_tokens=600)\n",
    "    print(\"✓ Parameters updated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Parameter update failed: {str(e)}\")\n",
    "\n",
    "# Test model change\n",
    "print(\"\\nTesting model change:\")\n",
    "try:\n",
    "    gateway.set_model(\"llama3.2:1b\")  # Or any other model you have\n",
    "    print(\"✓ Model changed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Model change failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758c4ce-1b3c-480c-bdbf-423f324e5189",
   "metadata": {},
   "source": [
    "# Corpus Manager Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eedbb32-0640-4211-bf8f-3d8d3c93d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpus_Manager import CorpusManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dba7ded-3bf9-4228-aa1b-1e4099aa9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:07:23,237 - Corpus_Manager - INFO - Successfully loaded corpus from corpus.json\n",
      "2025-02-18 18:07:23,238 - Corpus_Manager - ERROR - Main intent 'invalid_intent' not found in corpus\n",
      "2025-02-18 18:07:23,238 - Corpus_Manager - ERROR - Sub-intent 'invalid_sub_intent' not found under main intent 'admission_process'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Corpus Manager initialized successfully\n",
      "\n",
      "Validating corpus structure:\n",
      "Validation status: success\n",
      "\n",
      "Testing response retrieval:\n",
      "\n",
      "Test case - Main: admission_process, Sub: admission_deadline\n",
      "Status: success\n",
      "Main response: Hello! The admission process at [Institution Name] ...\n",
      "Sub response: The admission deadline for [Course/Program] at [In ...\n",
      "\n",
      "Test case - Main: admission_process, Sub: None\n",
      "Status: success\n",
      "Main response: Hello! The admission process at [Institution Name] ...\n",
      "\n",
      "Test case - Main: invalid_intent, Sub: None\n",
      "Status: error\n",
      "Error: Main intent 'invalid_intent' not found in corpus\n",
      "\n",
      "Test case - Main: admission_process, Sub: invalid_sub_intent\n",
      "Status: error\n",
      "Error: Sub-intent 'invalid_sub_intent' not found under main intent 'admission_process'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    manager = CorpusManager('corpus.json')\n",
    "    print(\"✓ Corpus Manager initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Corpus Manager initialization failed: {str(e)}\")\n",
    "\n",
    "# Test validation\n",
    "print(\"\\nValidating corpus structure:\")\n",
    "validation_result = manager.validate_intent_structure()\n",
    "print(f\"Validation status: {validation_result['status']}\")\n",
    "if validation_result['errors']:\n",
    "    print(\"Validation errors:\")\n",
    "    for error in validation_result['errors']:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    # Valid main and sub intent\n",
    "    ('admission_process', 'admission_deadline'),\n",
    "    # Valid main intent only\n",
    "    ('admission_process', None),\n",
    "    # Invalid main intent\n",
    "    ('invalid_intent', None),\n",
    "    # Invalid sub intent\n",
    "    ('admission_process', 'invalid_sub_intent'),\n",
    "]\n",
    "\n",
    "print(\"\\nTesting response retrieval:\")\n",
    "for main_intent, sub_intent in test_cases:\n",
    "    print(f\"\\nTest case - Main: {main_intent}, Sub: {sub_intent}\")\n",
    "    result = manager.get_response_text(main_intent, sub_intent)\n",
    "    print(f\"Status: {result['status']}\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(\"Main response:\", result['main_response'][:50], \"...\")\n",
    "        if result['sub_response']:\n",
    "            print(\"Sub response:\", result['sub_response'][:50], \"...\")\n",
    "    else:\n",
    "        print(\"Error:\", result.get('error', 'Unknown error'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c586842-b7db-420e-9435-53b62a4cf670",
   "metadata": {},
   "source": [
    "# Overall Test Before API/Containerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9191f24-ee63-440c-aae5-280dbdceb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Any\n",
    "from BERTClassifier import IntentClassifier\n",
    "from LLM_Gateway_Ollama import LLMGateway\n",
    "from Corpus_Manager import CorpusManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60408fe3-2e6e-4244-947e-e944583e65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ChatbotPipeline:\n",
    "    \"\"\"Test pipeline integrating all modules\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_path: str,\n",
    "                 corpus_path: str,\n",
    "                 confidence_threshold: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the test pipeline.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to BERT model\n",
    "            corpus_path: Path to corpus JSON\n",
    "            confidence_threshold: Confidence threshold for intent classification\n",
    "        \"\"\"\n",
    "        # Initialize all components\n",
    "        logger.info(\"Initializing components...\")\n",
    "        \n",
    "        self.classifier = IntentClassifier(\n",
    "            model_path=model_path,\n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "        \n",
    "        self.llm = LLMGateway(\n",
    "            base_url=\"http://127.0.0.1:11434\",\n",
    "            model=\"llama3.2:1b\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        self.corpus = CorpusManager(corpus_path)\n",
    "        logger.info(\"All components initialized successfully\")\n",
    "\n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a single query through the pipeline.\n",
    "        \n",
    "        Args:\n",
    "            query: User query text\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing processing results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Processing query: {query}\")\n",
    "            \n",
    "            # Step 1: Intent Classification\n",
    "            classification_result = self.classifier.predict(query)\n",
    "            logger.info(f\"Classification result: {classification_result}\")\n",
    "            \n",
    "            # Check if we should use LLM\n",
    "            if classification_result['status'] == 'llm_fallback':\n",
    "                logger.info(\"Query classified for LLM fallback\")\n",
    "                llm_response = self.llm.generate_response(query)\n",
    "                \n",
    "                return {\n",
    "                    'status': 'success',\n",
    "                    'source': 'llm',\n",
    "                    'response': llm_response.get('response'),\n",
    "                    'confidence': classification_result['confidence']\n",
    "                }\n",
    "            \n",
    "            # Step 2: Get response from corpus\n",
    "            elif classification_result['status'] == 'success':\n",
    "                logger.info(\"Query matched known intents, fetching from corpus\")\n",
    "                corpus_response = self.corpus.get_response_text(\n",
    "                    classification_result['main_intent'],\n",
    "                    classification_result['sub_intent']\n",
    "                )\n",
    "                \n",
    "                if corpus_response['status'] == 'success':\n",
    "                    return {\n",
    "                        'status': 'success',\n",
    "                        'source': 'corpus',\n",
    "                        'main_response': corpus_response['main_response'],\n",
    "                        'sub_response': corpus_response['sub_response'],\n",
    "                        'confidence': classification_result['confidence'],\n",
    "                        'intents': {\n",
    "                            'main': classification_result['main_intent'],\n",
    "                            'sub': classification_result['sub_intent']\n",
    "                        }\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        'status': 'error',\n",
    "                        'error': f\"Corpus error: {corpus_response.get('error')}\",\n",
    "                        'confidence': classification_result['confidence']\n",
    "                    }\n",
    "            \n",
    "            # Handle classification errors\n",
    "            else:\n",
    "                return {\n",
    "                    'status': 'error',\n",
    "                    'error': f\"Classification error: {classification_result.get('error')}\",\n",
    "                    'confidence': classification_result.get('confidence', {'main': 0.0, 'sub': 0.0})\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {str(e)}\")\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error': f\"Processing error: {str(e)}\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c327b4d-9a70-4c3d-b839-34af8f807606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:31:00,536 - __main__ - INFO - Initializing components...\n",
      "2025-02-18 18:31:00,537 - BERTClassifier - INFO - Using device: cpu\n",
      "2025-02-18 18:31:01,576 - BERTClassifier - INFO - Model successfully loaded from ../PT_NLU_Test1/models/erp_bot_t1.pt\n",
      "2025-02-18 18:31:01,579 - LLM_Gateway_Ollama - INFO - Successfully connected to Ollama server\n",
      "2025-02-18 18:31:01,580 - Corpus_Manager - INFO - Successfully loaded corpus from corpus.json\n",
      "2025-02-18 18:31:01,580 - __main__ - INFO - All components initialized successfully\n",
      "2025-02-18 18:31:01,604 - __main__ - INFO - Processing query: What's the deadline for admission?\n",
      "2025-02-18 18:31:01,722 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'admission_process', 'sub_intent': 'admission_deadline', 'confidence': {'main': 0.9378741383552551, 'sub': 0.4921603798866272}}\n",
      "2025-02-18 18:31:01,723 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-18 18:31:01,723 - __main__ - INFO - Processing query: Tell me about the admission process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pipeline initialized successfully\n",
      "\n",
      "\n",
      "Test Case 1: 'What's the deadline for admission?'\n",
      "--------------------------------------------------\n",
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The admission process at [Institution Name] involves several steps, including application submission, document verification, fee payment, and confirmation. How can I assist you with the admission process?\n",
      "\n",
      "Sub Intent Response:\n",
      "The admission deadline for [Course/Program] at [Institution Name] is [Deadline Date]. Ensure that you complete all necessary steps before this date. Would you like more details?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9379\n",
      "  Sub:  0.4922\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 2: 'Tell me about the admission process'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:31:01,842 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'admission_process', 'sub_intent': 'admission_deadline', 'confidence': {'main': 0.9639719128608704, 'sub': 0.2927125096321106}}\n",
      "2025-02-18 18:31:01,843 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-18 18:31:01,843 - __main__ - INFO - Processing query: What documents do I need for admission?\n",
      "2025-02-18 18:31:01,960 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'admission_process', 'sub_intent': 'admission_documents', 'confidence': {'main': 0.907092273235321, 'sub': 0.6718372702598572}}\n",
      "2025-02-18 18:31:01,960 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-18 18:31:01,961 - __main__ - INFO - Processing query: How much is the admission fee?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The admission process at [Institution Name] involves several steps, including application submission, document verification, fee payment, and confirmation. How can I assist you with the admission process?\n",
      "\n",
      "Sub Intent Response:\n",
      "The admission deadline for [Course/Program] at [Institution Name] is [Deadline Date]. Ensure that you complete all necessary steps before this date. Would you like more details?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9640\n",
      "  Sub:  0.2927\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 3: 'What documents do I need for admission?'\n",
      "--------------------------------------------------\n",
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The admission process at [Institution Name] involves several steps, including application submission, document verification, fee payment, and confirmation. How can I assist you with the admission process?\n",
      "\n",
      "Sub Intent Response:\n",
      "For admission, you will need the following documents:\n",
      "- [List of Required Documents]\n",
      "Please make sure to submit them in the required format. Do you need assistance with document submission?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9071\n",
      "  Sub:  0.6718\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 4: 'How much is the admission fee?'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:31:02,074 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'admission_process', 'sub_intent': 'admission_fee_details', 'confidence': {'main': 0.8764243721961975, 'sub': 0.7309731841087341}}\n",
      "2025-02-18 18:31:02,075 - __main__ - INFO - Query matched known intents, fetching from corpus\n",
      "2025-02-18 18:31:02,075 - __main__ - INFO - Processing query: How to make my professor sick so that I can avoid tomorrow's class test?\n",
      "2025-02-18 18:31:02,133 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.4073396623134613, 'sub': 0.0}, 'original_query': \"How to make my professor sick so that I can avoid tomorrow's class test?\"}\n",
      "2025-02-18 18:31:02,134 - __main__ - INFO - Query classified for LLM fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The admission process at [Institution Name] involves several steps, including application submission, document verification, fee payment, and confirmation. How can I assist you with the admission process?\n",
      "\n",
      "Sub Intent Response:\n",
      "The admission fee for [Course/Program] is [Fee Amount]. You can make the payment via [Payment Methods]. Would you like assistance with the payment process?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.8764\n",
      "  Sub:  0.7310\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 5: 'How to make my professor sick so that I can avoid tomorrow's class test?'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:31:04,736 - __main__ - INFO - Processing query: Tell me a joke about RUST programming\n",
      "2025-02-18 18:31:04,816 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.11446689069271088, 'sub': 0.0}, 'original_query': 'Tell me a joke about RUST programming'}\n",
      "2025-02-18 18:31:04,817 - __main__ - INFO - Query classified for LLM fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "I can't provide information or guidance on harmful behavior such as attempting to make your professor sick. \n",
      "\n",
      "If you're struggling with the material or need help, consider reaching out to your professor or teaching assistant for support. They may be able to provide additional resources or clarification on the course material. If you're experiencing difficulties with coursework, I encourage you to discuss this with them directly. There are also student advocacy services and counseling resources available that can offer guidance and support.\n",
      "\n",
      "Is there anything else I can help you with?\n",
      "\n",
      "Confidence Score: 0.4073\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 6: 'Tell me a joke about RUST programming'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:31:05,015 - __main__ - INFO - Processing query: How to calculate 5 times 6?\n",
      "2025-02-18 18:31:05,078 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.14254972338676453, 'sub': 0.0}, 'original_query': 'How to calculate 5 times 6?'}\n",
      "2025-02-18 18:31:05,078 - __main__ - INFO - Query classified for LLM fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "Here's one:\n",
      "\n",
      "Why did the Rust programmer quit his job?\n",
      "\n",
      "Because he didn't get type safety out of it.\n",
      "\n",
      "(Sorry, I know it's a bit of a \"bug\" – I couldn't resist the pun!)\n",
      "\n",
      "Confidence Score: 0.1145\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 7: 'How to calculate 5 times 6?'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:31:05,220 - __main__ - INFO - Processing query: \n",
      "2025-02-18 18:31:05,220 - __main__ - INFO - Classification result: {'status': 'error', 'error': 'Empty or invalid input text', 'confidence': {'main': 0.0, 'sub': 0.0}}\n",
      "2025-02-18 18:31:05,221 - __main__ - INFO - Processing query: ???\n",
      "2025-02-18 18:31:05,285 - __main__ - INFO - Classification result: {'status': 'llm_fallback', 'confidence': {'main': 0.2581322193145752, 'sub': 0.0}, 'original_query': '???'}\n",
      "2025-02-18 18:31:05,285 - __main__ - INFO - Query classified for LLM fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "To calculate 5 times 6, you can simply multiply the two numbers together. \n",
      "\n",
      "5 * 6 = 30\n",
      "\n",
      "Confidence Score: 0.1425\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 8: ''\n",
      "--------------------------------------------------\n",
      "Status: error\n",
      "Source: N/A\n",
      "Error: Classification error: Empty or invalid input text\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 9: '???'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:31:05,472 - __main__ - INFO - Processing query: I need help with my admission but I'm not sure what exactly to ask\n",
      "2025-02-18 18:31:05,593 - __main__ - INFO - Classification result: {'status': 'success', 'main_intent': 'admission_process', 'sub_intent': 'admission_status', 'confidence': {'main': 0.9397178888320923, 'sub': 0.4698791205883026}}\n",
      "2025-02-18 18:31:05,594 - __main__ - INFO - Query matched known intents, fetching from corpus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Source: llm\n",
      "\n",
      "LLM Response:\n",
      "It seems like you're asking a question, but it's not clear what you're inquiring about. Could you please provide more context or information so I can better understand and provide a helpful response?\n",
      "\n",
      "Confidence Score: 0.2581\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Case 10: 'I need help with my admission but I'm not sure what exactly to ask'\n",
      "--------------------------------------------------\n",
      "Status: success\n",
      "Source: corpus\n",
      "\n",
      "Main Intent Response:\n",
      "Hello! The admission process at [Institution Name] involves several steps, including application submission, document verification, fee payment, and confirmation. How can I assist you with the admission process?\n",
      "\n",
      "Sub Intent Response:\n",
      "You can check your admission status by visiting [Admission Portal Link] and entering your application number. Would you like me to guide you through the process?\n",
      "\n",
      "Confidence Scores:\n",
      "  Main: 0.9397\n",
      "  Sub:  0.4699\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pipeline = ChatbotPipeline(\n",
    "        model_path='../PT_NLU_Test1/models/erp_bot_t1.pt',\n",
    "        corpus_path='corpus.json',\n",
    "        confidence_threshold=0.7\n",
    "    )\n",
    "    print(\"✓ Pipeline initialized successfully\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Pipeline initialization failed: {str(e)}\")\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    # In-domain queries (should use corpus)\n",
    "    \"What's the deadline for admission?\",\n",
    "    \"Tell me about the admission process\",\n",
    "    \"What documents do I need for admission?\",\n",
    "    \"How much is the admission fee?\",\n",
    "    \n",
    "    #Out-of-domain queries (should use LLM)\n",
    "    \"How to make my professor sick so that I can avoid tomorrow's class test?\",\n",
    "    \"Tell me a joke about RUST programming\",\n",
    "    \"How to calculate 5 times 6?\",\n",
    "    \n",
    "    #Edge cases\n",
    "    \"\",  # Empty query\n",
    "    \"???\",  # Nonsense query\n",
    "    \"I need help with my admission but I'm not sure what exactly to ask\"  # Ambiguous query\n",
    "]\n",
    "\n",
    "# Process each test query\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nTest Case {i}: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    result = pipeline.process_query(query)\n",
    "    \n",
    "    print(f\"Status: {result['status']}\")\n",
    "    print(f\"Source: {result.get('source', 'N/A')}\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        if result['source'] == 'corpus':\n",
    "            print(\"\\nMain Intent Response:\")\n",
    "            print(result['main_response'])\n",
    "            if result['sub_response']:\n",
    "                print(\"\\nSub Intent Response:\")\n",
    "                print(result['sub_response'])\n",
    "            print(f\"\\nConfidence Scores:\")\n",
    "            print(f\"  Main: {result['confidence']['main']:.4f}\")\n",
    "            print(f\"  Sub:  {result['confidence']['sub']:.4f}\")\n",
    "        else:  # LLM response\n",
    "            print(\"\\nLLM Response:\")\n",
    "            print(result['response'])\n",
    "            print(f\"\\nConfidence Score: {result['confidence']['main']:.4f}\")\n",
    "    else:\n",
    "        print(f\"Error: {result.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40422e2a-c212-41a0-a904-4dac9042fb93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
